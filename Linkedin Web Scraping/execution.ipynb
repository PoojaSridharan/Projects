{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "from impfunctions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lists of countries and job titles\n",
    "countries = [\n",
    "    \"United States\",\n",
    "    \"India\",\n",
    "    \"United Kingdom\",\n",
    "    \"Germany\",\n",
    "    \"Canada\",\n",
    "    \"Australia\",\n",
    "    \"Singapore\",\n",
    "    \"Netherlands\",\n",
    "    \"France\",\n",
    "    \"China\"\n",
    "]\n",
    "\n",
    "job_titles = [\n",
    "    \"data analyst\",\n",
    "    \"data scientist\",\n",
    "    \"business analyst\"\n",
    "]\n",
    "\n",
    "# Create a list of tuples for each combination of country and job title\n",
    "country_job_combinations = list(itertools.product(countries, job_titles))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating chrome driver with necessary options\n",
    "chrome_option = Options()\n",
    "service = Service(executable_path=r\"C:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\chromedriver-win64\\chromedriver.exe\")\n",
    "chrome_option.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "chrome_option.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "chrome_option.add_argument('--incognito')\n",
    "chrome_option.add_argument('--disable-web-security')\n",
    "# wd1 = webdriver.Chrome(service=service , options = chrome_option )\n",
    "# wd1.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:11: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 11 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:27: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 27 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup1=BeautifulSoup(url1.content)\n",
      "c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:31: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 31 of the file c:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(page_source)\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00007FF720FEB5D2+29090]\n\t(No symbol) [0x00007FF720F5E689]\n\t(No symbol) [0x00007FF720E1B1CA]\n\t(No symbol) [0x00007FF720DEFAF5]\n\t(No symbol) [0x00007FF720E9E2E7]\n\t(No symbol) [0x00007FF720EB5EE1]\n\t(No symbol) [0x00007FF720E96493]\n\t(No symbol) [0x00007FF720E609B1]\n\t(No symbol) [0x00007FF720E61B11]\n\tGetHandleVerifier [0x00007FF721308C5D+3295277]\n\tGetHandleVerifier [0x00007FF721354843+3605523]\n\tGetHandleVerifier [0x00007FF72134A707+3564247]\n\tGetHandleVerifier [0x00007FF7210A6EB6+797318]\n\t(No symbol) [0x00007FF720F6980F]\n\t(No symbol) [0x00007FF720F653F4]\n\t(No symbol) [0x00007FF720F65580]\n\t(No symbol) [0x00007FF720F54A1F]\n\tBaseThreadInitThunk [0x00007FFA1CAD257D+29]\n\tRtlUserThreadStart [0x00007FFA1E7AAF28+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m wd1\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m df1\u001b[38;5;241m=\u001b[39m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwd1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Create CSV if it doesn't exist\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     df1\u001b[38;5;241m.\u001b[39mto_csv(file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\main.py:9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(wd1, jobtitle, joblocation)\u001b[0m\n\u001b[0;32m      7\u001b[0m wd1\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      8\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mscrapping_link\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwd1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m page_source\u001b[38;5;241m=\u001b[39mwd1\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     11\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page_source)\n",
      "File \u001b[1;32mc:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:83\u001b[0m, in \u001b[0;36mscrapping_link\u001b[1;34m(link, wd1)\u001b[0m\n\u001b[0;32m     81\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     last_height\u001b[38;5;241m=\u001b[39m\u001b[43minfinite_scroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwd1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m find_and_click_see_more_jobs(last_height,wd1):\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\Linkedin Web Scraping\\impfunctions.py:29\u001b[0m, in \u001b[0;36minfinite_scroll\u001b[1;34m(wd1)\u001b[0m\n\u001b[0;32m     26\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Adjust this time as needed\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate new scroll height and compare with last scroll height\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m new_height \u001b[38;5;241m=\u001b[39m \u001b[43mwd1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn document.body.scrollHeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m page_source\u001b[38;5;241m=\u001b[39mwd1\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     31\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page_source)\n",
      "File \u001b[1;32mc:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\virtenv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:414\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    411\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    412\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\virtenv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\sridh\\OneDrive\\Desktop\\Projects\\Projects\\virtenv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=128.0.6613.120)\nStacktrace:\n\tGetHandleVerifier [0x00007FF720FEB5D2+29090]\n\t(No symbol) [0x00007FF720F5E689]\n\t(No symbol) [0x00007FF720E1B1CA]\n\t(No symbol) [0x00007FF720DEFAF5]\n\t(No symbol) [0x00007FF720E9E2E7]\n\t(No symbol) [0x00007FF720EB5EE1]\n\t(No symbol) [0x00007FF720E96493]\n\t(No symbol) [0x00007FF720E609B1]\n\t(No symbol) [0x00007FF720E61B11]\n\tGetHandleVerifier [0x00007FF721308C5D+3295277]\n\tGetHandleVerifier [0x00007FF721354843+3605523]\n\tGetHandleVerifier [0x00007FF72134A707+3564247]\n\tGetHandleVerifier [0x00007FF7210A6EB6+797318]\n\t(No symbol) [0x00007FF720F6980F]\n\t(No symbol) [0x00007FF720F653F4]\n\t(No symbol) [0x00007FF720F65580]\n\t(No symbol) [0x00007FF720F54A1F]\n\tBaseThreadInitThunk [0x00007FFA1CAD257D+29]\n\tRtlUserThreadStart [0x00007FFA1E7AAF28+40]\n"
     ]
    }
   ],
   "source": [
    "for i,j in country_job_combinations:\n",
    "    wd1 = webdriver.Chrome(service=service , options = chrome_option )\n",
    "    wd1.maximize_window()\n",
    "    file_path = 'data.csv'\n",
    "    df1=main(wd1,j,i)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create CSV if it doesn't exist\n",
    "        df1.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        # Append to CSV if it exists\n",
    "        df1.to_csv(file_path, mode='a', header=False, index=False)\n",
    "    wd1.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
